{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Implementation\n",
    "\n",
    "This notebook implements a Graph-based RAG system using Neptune for graph storage and hybrid search combining graph and vector retrieval.\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "### Document Processing\n",
    "- chunk_size: Number of words per chunk (default: 500)\n",
    "- chunk_overlap: Number of overlapping words between chunks (default: 50)\n",
    "- enable_chunking: Whether to split documents into chunks (default: True)\n",
    "\n",
    "### Graph Construction\n",
    "- min_entity_freq: Minimum frequency for entity inclusion (default: 2)\n",
    "- max_relation_distance: Maximum token distance for relationship extraction (default: 10)\n",
    "- confidence_threshold: Minimum confidence for extracted relations (default: 0.5)\n",
    "\n",
    "### Hybrid Search\n",
    "- k_graph: Number of graph-based results to retrieve (default: 5)\n",
    "- k_vector: Number of vector-based results to retrieve (default: 3)\n",
    "- alpha: Weight for combining graph and vector scores (default: 0.7)\n",
    "\n",
    "### Neptune Settings\n",
    "- instance_type: Neptune instance type (default: 'db.r6g.xlarge')\n",
    "- enable_audit: Enable audit logging (default: True)\n",
    "\n",
    "### API Settings\n",
    "- max_retries: Maximum number of retry attempts (default: 5)\n",
    "- min_delay: Minimum delay between retries in seconds (default: 1)\n",
    "- max_delay: Maximum delay between retries in seconds (default: 60)\n",
    "\n",
    "## Prerequisites\n",
    "- Run setup.ipynb first to configure environment\n",
    "- Neptune cluster must be configured\n",
    "- SpaCy model must be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import boto3\n",
    "import spacy\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path(\"../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import utilities\n",
    "from utils.aws.opensearch_utils import OpenSearchManager\n",
    "from utils.aws.neptune_utils import NeptuneManager, NeptuneGraph\n",
    "from utils.metrics.bedrock_llm import BedrockLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class GraphRAG:\n",
    "    \"\"\"\n",
    "    Graph-based RAG implementation using Neptune for graph storage and hybrid search.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        index_name: str,\n",
    "        chunk_size: int = 500,\n",
    "        chunk_overlap: int = 50,\n",
    "        enable_chunking: bool = True,\n",
    "        min_entity_freq: int = 2,\n",
    "        max_relation_distance: int = 10,\n",
    "        confidence_threshold: float = 0.5,\n",
    "        k_graph: int = 5,\n",
    "        k_vector: int = 3,\n",
    "        alpha: float = 0.7,\n",
    "        instance_type: str = \"db.r6g.xlarge\",\n",
    "        enable_audit: bool = True,\n",
    "        max_retries: int = 5,\n",
    "        min_delay: float = 1.0,\n",
    "        max_delay: float = 60.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize GraphRAG with configuration parameters.\n",
    "        \n",
    "        Args:\n",
    "            index_name: Name for the OpenSearch index (vector store)\n",
    "            chunk_size: Number of words per chunk\n",
    "            chunk_overlap: Number of overlapping words between chunks\n",
    "            enable_chunking: Whether to split documents into chunks\n",
    "            min_entity_freq: Minimum frequency for entity inclusion\n",
    "            max_relation_distance: Maximum token distance for relationships\n",
    "            confidence_threshold: Minimum confidence for extracted relations\n",
    "            k_graph: Number of graph-based results to retrieve\n",
    "            k_vector: Number of vector-based results to retrieve\n",
    "            alpha: Weight for combining graph and vector scores (0-1)\n",
    "            instance_type: Neptune instance type\n",
    "            enable_audit: Enable audit logging\n",
    "            max_retries: Maximum retry attempts\n",
    "            min_delay: Minimum retry delay in seconds\n",
    "            max_delay: Maximum retry delay in seconds\n",
    "        \"\"\"\n",
    "        self.index_name = index_name\n",
    "        \n",
    "        # Document processing config\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.enable_chunking = enable_chunking\n",
    "        \n",
    "        # Graph construction config\n",
    "        self.min_entity_freq = min_entity_freq\n",
    "        self.max_relation_distance = max_relation_distance\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # Search config\n",
    "        self.k_graph = k_graph\n",
    "        self.k_vector = k_vector\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Neptune config\n",
    "        self.instance_type = instance_type\n",
    "        self.enable_audit = enable_audit\n",
    "        \n",
    "        # API config\n",
    "        self.max_retries = max_retries\n",
    "        self.min_delay = min_delay\n",
    "        self.max_delay = max_delay\n",
    "        \n",
    "        # Initialize components\n",
    "        self._init_nlp()\n",
    "        self._init_graph_store()\n",
    "        self._init_vector_store()\n",
    "        self._init_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "    def _init_nlp(self):\n",
    "        \"\"\"Initialize SpaCy for entity and relation extraction.\"\"\"\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            print(\"Downloading SpaCy model...\")\n",
    "            os.system(\"python -m spacy download en_core_web_sm\")\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    def _init_graph_store(self):\n",
    "        \"\"\"Initialize Neptune graph store connection.\"\"\"\n",
    "        # Set up Neptune cluster\n",
    "        self.neptune_manager = NeptuneManager(\n",
    "            cluster_name=f\"graph-rag-{self.index_name}\",\n",
    "            instance_type=self.instance_type,\n",
    "            cleanup_enabled=True\n",
    "        )\n",
    "        endpoint = self.neptune_manager.setup_cluster()\n",
    "        \n",
    "        # Initialize graph interface\n",
    "        self.graph = NeptuneGraph(endpoint)\n",
    "    \n",
    "    def _init_vector_store(self):\n",
    "        \"\"\"Initialize OpenSearch vector store connection.\"\"\"\n",
    "        self.opensearch = OpenSearchManager(\n",
    "            domain_name=f\"graph-rag-{self.index_name}\",\n",
    "            cleanup_enabled=True\n",
    "        )\n",
    "        endpoint = self.opensearch.setup_domain()\n",
    "        \n",
    "        # Create index with vector search settings\n",
    "        index_settings = {\n",
    "            \"settings\": {\n",
    "                \"index\": {\n",
    "                    \"knn\": True,\n",
    "                    \"knn.algo_param.ef_search\": 512\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"content\": {\"type\": \"text\"},\n",
    "                    \"vector\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 1024,\n",
    "                        \"method\": {\n",
    "                            \"name\": \"hnsw\",\n",
    "                            \"space_type\": \"cosinesimil\",\n",
    "                            \"engine\": \"nmslib\",\n",
    "                            \"parameters\": {\n",
    "                                \"ef_construction\": 512,\n",
    "                                \"m\": 16\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.opensearch.create_index(\n",
    "            index_name=self.index_name,\n",
    "            settings=index_settings\n",
    "        )\n",
    "    \n",
    "    def _init_llm(self):\n",
    "        \"\"\"Initialize Bedrock LLM for response generation.\"\"\"\n",
    "        self.llm = BedrockLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "    def _extract_entities_relations(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract entities and relations from text using SpaCy.\n",
    "        \n",
    "        Args:\n",
    "            text: Input text to process\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing extracted entities and relations\n",
    "        \"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        \n",
    "        # Extract entities\n",
    "        entities = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"DATE\", \"EVENT\"]:\n",
    "                entities.append({\n",
    "                    \"text\": ent.text,\n",
    "                    \"label\": ent.label_,\n",
    "                    \"start\": ent.start_char,\n",
    "                    \"end\": ent.end_char\n",
    "                })\n",
    "        \n",
    "        # Extract relations\n",
    "        relations = []\n",
    "        for token in doc:\n",
    "            if token.dep_ == \"ROOT\":\n",
    "                for child in token.children:\n",
    "                    if child.dep_ in [\"nsubj\", \"dobj\"]:\n",
    "                        relations.append({\n",
    "                            \"subject\": child.text,\n",
    "                            \"predicate\": token.text,\n",
    "                            \"object\": next((c.text for c in token.children \n",
    "                                          if c.dep_ in [\"dobj\", \"pobj\"]), None)\n",
    "                        })\n",
    "        \n",
    "        return {\n",
    "            \"entities\": entities,\n",
    "            \"relations\": relations\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "    def _store_graph_data(self, doc_id: str, graph_data: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Store extracted entities and relations in Neptune.\n",
    "        \n",
    "        Args:\n",
    "            doc_id: Document identifier\n",
    "            graph_data: Dictionary containing entities and relations\n",
    "        \"\"\"\n",
    "        # Create document vertex\n",
    "        doc_vertex_id = self.graph.add_vertex(\n",
    "            label=\"Document\",\n",
    "            properties={\"id\": doc_id},\n",
    "            id=doc_id\n",
    "        )\n",
    "        \n",
    "        # Add entities\n",
    "        entity_ids = {}\n",
    "        for entity in graph_data[\"entities\"]:\n",
    "            # Create unique ID for entity\n",
    "            entity_id = f\"{entity['text']}_{entity['label']}\"\n",
    "            \n",
    "            # Add entity vertex if it doesn't exist\n",
    "            if entity_id not in entity_ids:\n",
    "                entity_ids[entity_id] = self.graph.add_vertex(\n",
    "                    label=entity[\"label\"],\n",
    "                    properties={\n",
    "                        \"text\": entity[\"text\"],\n",
    "                        \"label\": entity[\"label\"]\n",
    "                    },\n",
    "                    id=entity_id\n",
    "                )\n",
    "            \n",
    "            # Link entity to document\n",
    "            self.graph.add_edge(\n",
    "                from_id=doc_vertex_id,\n",
    "                to_id=entity_ids[entity_id],\n",
    "                label=\"CONTAINS\",\n",
    "                properties={\n",
    "                    \"start\": entity[\"start\"],\n",
    "                    \"end\": entity[\"end\"]\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        # Add relations\n",
    "        for relation in graph_data[\"relations\"]:\n",
    "            if relation[\"object\"]:\n",
    "                # Create relation edge between entities\n",
    "                subject_matches = self.graph.get_vertices(\n",
    "                    properties={\"text\": relation[\"subject\"]}\n",
    "                )\n",
    "                object_matches = self.graph.get_vertices(\n",
    "                    properties={\"text\": relation[\"object\"]}\n",
    "                )\n",
    "                \n",
    "                if subject_matches and object_matches:\n",
    "                    self.graph.add_edge(\n",
    "                        from_id=subject_matches[0][\"id\"],\n",
    "                        to_id=object_matches[0][\"id\"],\n",
    "                        label=relation[\"predicate\"].upper(),\n",
    "                        properties={\n",
    "                            \"document\": doc_id,\n",
    "                            \"confidence\": self.confidence_threshold\n",
    "                        }\n",
    "                    )\n",
    "    \n",
    "    def _vector_search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform vector similarity search using OpenSearch.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents with scores\n",
    "        \"\"\"\n",
    "        # Get query embedding from Bedrock\n",
    "        query_embedding = self.llm.get_embedding(query)\n",
    "        \n",
    "        # Perform k-NN search\n",
    "        search_query = {\n",
    "            \"size\": self.k_vector,\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"vector\": {\n",
    "                        \"vector\": query_embedding,\n",
    "                        \"k\": self.k_vector\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        results = self.opensearch.search(\n",
    "            index=self.index_name,\n",
    "            body=search_query\n",
    "        )\n",
    "        \n",
    "        # Format results\n",
    "        vector_results = []\n",
    "        for hit in results[\"hits\"][\"hits\"]:\n",
    "            vector_results.append({\n",
    "                \"id\": hit[\"_id\"],\n",
    "                \"score\": hit[\"_score\"],\n",
    "                \"content\": hit[\"_source\"][\"content\"],\n",
    "                \"source\": \"vector\"\n",
    "            })\n",
    "        \n",
    "        return vector_results\n",
    "    \n",
    "    def _hybrid_search(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform hybrid search combining graph and vector retrieval.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents with scores\n",
    "        \"\"\"\n",
    "        # Extract entities from query\n",
    "        query_graph = self._extract_entities_relations(query)\n",
    "        \n",
    "        # Get graph-based results\n",
    "        graph_results = []\n",
    "        for entity in query_graph[\"entities\"]:\n",
    "            # Find matching entity vertices\n",
    "            matches = self.graph.get_vertices(\n",
    "                properties={\"text\": entity[\"text\"]}\n",
    "            )\n",
    "            \n",
    "            for match in matches:\n",
    "                # Get connected documents\n",
    "                docs = self.graph.get_neighbors(\n",
    "                    vertex_id=match[\"id\"],\n",
    "                    direction=\"in\",\n",
    "                    edge_label=\"CONTAINS\",\n",
    "                    limit=self.k_graph\n",
    "                )\n",
    "                \n",
    "                for doc in docs:\n",
    "                    graph_results.append({\n",
    "                        \"id\": doc[\"id\"],\n",
    "                        \"score\": 1.0,  # TODO: Implement graph scoring\n",
    "                        \"source\": \"graph\"\n",
    "                    })\n",
    "        \n",
    "        # Get vector-based results\n",
    "        vector_results = self._vector_search(query)\n",
    "        \n",
    "        # Combine results\n",
    "        combined_results = self._merge_results(graph_results, vector_results)\n",
    "        \n",
    "        return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "    def _merge_results(\n",
    "        self,\n",
    "        graph_results: List[Dict[str, Any]],\n",
    "        vector_results: List[Dict[str, Any]]\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Merge graph and vector search results using weighted scoring.\n",
    "        \n",
    "        Args:\n",
    "            graph_results: Results from graph search\n",
    "            vector_results: Results from vector search\n",
    "            \n",
    "        Returns:\n",
    "            Combined and re-ranked results\n",
    "        \"\"\"\n",
    "        # Combine all results\n",
    "        all_results = {}\n",
    "        \n",
    "        # Add graph results\n",
    "        for result in graph_results:\n",
    "            if result[\"id\"] not in all_results:\n",
    "                all_results[result[\"id\"]] = {\n",
    "                    \"id\": result[\"id\"],\n",
    "                    \"graph_score\": result[\"score\"],\n",
    "                    \"vector_score\": 0.0\n",
    "                }\n",
    "        \n",
    "        # Add vector results\n",
    "        for result in vector_results:\n",
    "            if result[\"id\"] not in all_results:\n",
    "                all_results[result[\"id\"]] = {\n",
    "                    \"id\": result[\"id\"],\n",
    "                    \"graph_score\": 0.0,\n",
    "                    \"vector_score\": result[\"score\"]\n",
    "                }\n",
    "            else:\n",
    "                all_results[result[\"id\"]][\"vector_score\"] = result[\"score\"]\n",
    "        \n",
    "        # Calculate combined scores\n",
    "        results = []\n",
    "        for doc_id, scores in all_results.items():\n",
    "            combined_score = (\n",
    "                self.alpha * scores[\"graph_score\"] +\n",
    "                (1 - self.alpha) * scores[\"vector_score\"]\n",
    "            )\n",
    "            results.append({\n",
    "                \"id\": doc_id,\n",
    "                \"score\": combined_score,\n",
    "                \"graph_score\": scores[\"graph_score\"],\n",
    "                \"vector_score\": scores[\"vector_score\"]\n",
    "            })\n",
    "        \n",
    "        # Sort by combined score\n",
    "        results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        \n",
    "        return results[:self.k_vector]\n",
    "    \n",
    "    def query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Process a query using graph-augmented retrieval.\n",
    "        \n",
    "        Args:\n",
    "            query: User query\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing response and context\n",
    "        \"\"\"\n",
    "        # Get relevant documents\n",
    "        results = self._hybrid_search(query)\n",
    "        \n",
    "        # Extract graph context\n",
    "        graph_context = []\n",
    "        for result in results:\n",
    "            # Get entities and relations for document\n",
    "            doc_entities = self.graph.get_neighbors(\n",
    "                vertex_id=result[\"id\"],\n",
    "                direction=\"out\",\n",
    "                edge_label=\"CONTAINS\"\n",
    "            )\n",
    "            \n",
    "            doc_relations = []\n",
    "            for entity in doc_entities:\n",
    "                relations = self.graph.get_edges(\n",
    "                    properties={\"document\": result[\"id\"]}\n",
    "                )\n",
    "                doc_relations.extend(relations)\n",
    "            \n",
    "            graph_context.append({\n",
    "                \"doc_id\": result[\"id\"],\n",
    "                \"entities\": doc_entities,\n",
    "                \"relations\": doc_relations\n",
    "            })\n",
    "        \n",
    "        # Format prompt with graph context\n",
    "        prompt = self._format_prompt(query, results, graph_context)\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.llm.generate(prompt)\n",
    "        \n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"context\": results,\n",
    "            \"graph_context\": graph_context\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "    def _format_prompt(\n",
    "        self,\n",
    "        query: str,\n",
    "        results: List[Dict[str, Any]],\n",
    "        graph_context: List[Dict[str, Any]]\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Format prompt with retrieved context and graph information.\n",
    "        \n",
    "        Args:\n",
    "            query: Original query\n",
    "            results: Retrieved documents\n",
    "            graph_context: Graph relationships\n",
    "            \n",
    "        Returns:\n",
    "            Formatted prompt string\n",
    "        \"\"\"\n",
    "        # Format document context\n",
    "        doc_context = \"\\n\\n\".join(r[\"content\"] for r in results)\n",
    "        \n",
    "        # Format graph context\n",
    "        graph_sections = []\n",
    "        for ctx in graph_context:\n",
    "            # Format entities\n",
    "            entities = [f\"{e['text']} ({e['label']})\" for e in ctx[\"entities\"]]\n",
    "            \n",
    "            # Format relations\n",
    "            relations = [\n",
    "                f\"{r['from']} {r['label']} {r['to']}\"\n",
    "                for r in ctx[\"relations\"]\n",
    "            ]\n",
    "            \n",
    "            section = f\"Document {ctx['doc_id']}:\\n\"\n",
    "            section += \"Entities: \" + \", \".join(entities) + \"\\n\"\n",
    "            section += \"Relations: \" + \", \".join(relations)\n",
    "            graph_sections.append(section)\n",
    "        \n",
    "        graph_text = \"\\n\\n\".join(graph_sections)\n",
    "        \n",
    "        prompt = f\"\"\"Use the following information to answer the question.\n",
    "\n",
    "Document Context:\n",
    "{doc_context}\n",
    "\n",
    "Graph Context:\n",
    "{graph_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        return prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
