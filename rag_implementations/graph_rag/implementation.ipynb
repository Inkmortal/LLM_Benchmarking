{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Implementation\n",
    "\n",
    "This notebook implements a Graph-based RAG system using Neptune for graph storage and hybrid search combining graph and vector retrieval.\n",
    "\n",
    "## Features\n",
    "- Document processing with entity/relation extraction\n",
    "- Graph storage in Neptune\n",
    "- Vector storage in OpenSearch\n",
    "- Hybrid search combining graph and vector similarity\n",
    "- Context-aware response generation\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "### Document Processing\n",
    "- chunk_size: Number of words per chunk (default: 500)\n",
    "- chunk_overlap: Number of overlapping words between chunks (default: 50)\n",
    "- enable_chunking: Whether to split documents into chunks (default: True)\n",
    "\n",
    "### Graph Construction\n",
    "- min_entity_freq: Minimum frequency for entity inclusion (default: 2)\n",
    "- max_relation_distance: Maximum token distance for relationships (default: 10)\n",
    "\n",
    "### Hybrid Search\n",
    "- k_graph: Number of graph-based results (default: 5)\n",
    "- k_vector: Number of vector-based results (default: 3)\n",
    "- alpha: Weight for combining scores (default: 0.7)\n",
    "- search_type: Type of vector search ('script' or 'knn', default: 'script')\n",
    "- similarity_threshold: Minimum similarity score (default: None)\n",
    "\n",
    "### API Settings\n",
    "- max_retries: Maximum retry attempts (default: 5)\n",
    "- min_delay: Minimum retry delay in seconds (default: 1)\n",
    "- max_delay: Maximum retry delay in seconds (default: 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Literal\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path(\"../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import components\n",
    "from rag_implementations.graph_rag.components.document_processor import DocumentProcessor\n",
    "from rag_implementations.graph_rag.components.graph_store import GraphStore\n",
    "from rag_implementations.graph_rag.components.vector_store import VectorStore\n",
    "from rag_implementations.graph_rag.components.hybrid_search import HybridSearch\n",
    "from rag_implementations.graph_rag.components.response_generator import ResponseGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class GraphRAG:\n",
    "    \"\"\"Graph-based RAG implementation using Neptune and OpenSearch.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        index_name: str,\n",
    "        # Document processing config\n",
    "        chunk_size: int = 500,\n",
    "        chunk_overlap: int = 50,\n",
    "        enable_chunking: bool = True,\n",
    "        # Graph construction config\n",
    "        min_entity_freq: int = 2,\n",
    "        max_relation_distance: int = 10,\n",
    "        # Hybrid search config\n",
    "        k_graph: int = 5,\n",
    "        k_vector: int = 3,\n",
    "        alpha: float = 0.7,\n",
    "        search_type: Literal['script', 'knn'] = 'script',\n",
    "        similarity_threshold: Optional[float] = None,\n",
    "        # OpenSearch config\n",
    "        index_settings: Optional[Dict] = None,\n",
    "        knn_params: Optional[Dict] = None,\n",
    "        # Neptune config\n",
    "        enable_audit: bool = True,\n",
    "        # API config\n",
    "        max_retries: int = 5,\n",
    "        min_delay: float = 1.0,\n",
    "        max_delay: float = 60.0\n",
    "    ):\n",
    "        \"\"\"Initialize GraphRAG with configuration parameters.\"\"\"\n",
    "        self.index_name = index_name\n",
    "        \n",
    "        # Initialize components\n",
    "        self.doc_processor = DocumentProcessor(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            enable_chunking=enable_chunking,\n",
    "            min_entity_freq=min_entity_freq,\n",
    "            max_relation_distance=max_relation_distance\n",
    "        )\n",
    "        \n",
    "        self.graph_store = GraphStore(\n",
    "            cluster_name=f\"graph-rag-{index_name}\",\n",
    "            enable_audit=enable_audit\n",
    "        )\n",
    "        \n",
    "        self.vector_store = VectorStore(\n",
    "            index_name=index_name,\n",
    "            search_type=search_type,\n",
    "            similarity_threshold=similarity_threshold,\n",
    "            index_settings=index_settings,\n",
    "            knn_params=knn_params\n",
    "        )\n",
    "        \n",
    "        self.hybrid_search = HybridSearch(\n",
    "            graph_store=self.graph_store,\n",
    "            vector_store=self.vector_store,\n",
    "            k_graph=k_graph,\n",
    "            k_vector=k_vector,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        \n",
    "        self.response_generator = ResponseGenerator(\n",
    "            max_retries=max_retries,\n",
    "            min_delay=min_delay,\n",
    "            max_delay=max_delay\n",
    "        )\n",
    "    \n",
    "    def query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a query using graph-augmented retrieval.\n",
    "        \n",
    "        Args:\n",
    "            query: User query\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing response and context\n",
    "        \"\"\"\n",
    "        # Extract entities from query\n",
    "        query_graph = self.doc_processor._extract_entities_relations(query)\n",
    "        \n",
    "        # Get query embedding\n",
    "        query_vector = self.response_generator.llm.get_embedding(query)\n",
    "        \n",
    "        # Perform hybrid search\n",
    "        search_results = self.hybrid_search.search(\n",
    "            query_text=query,\n",
    "            query_vector=query_vector,\n",
    "            query_entities=query_graph[\"entities\"]\n",
    "        )\n",
    "        \n",
    "        # Get graph context for each result\n",
    "        graph_context = []\n",
    "        for result in search_results:\n",
    "            doc_entities = self.graph_store.get_document_entities(result[\"id\"])\n",
    "            doc_relations = self.graph_store.get_document_relations(result[\"id\"])\n",
    "            \n",
    "            graph_context.append({\n",
    "                \"doc_id\": result[\"id\"],\n",
    "                \"entities\": doc_entities,\n",
    "                \"relations\": doc_relations\n",
    "            })\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.response_generator.generate(\n",
    "            query=query,\n",
    "            search_results=search_results,\n",
    "            graph_context=graph_context\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"response\": response,\n",
    "            \"context\": search_results,\n",
    "            \"graph_context\": graph_context\n",
    "        }\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        self.graph_store.cleanup()\n",
    "        self.vector_store.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
