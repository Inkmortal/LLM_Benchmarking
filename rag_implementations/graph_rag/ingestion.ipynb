{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Document Ingestion\n",
    "\n",
    "This notebook handles document processing and graph construction for the GraphRAG implementation.\n",
    "\n",
    "## Process Overview\n",
    "1. Load and preprocess documents using Langchain\n",
    "2. Extract entities and relationships\n",
    "3. Construct knowledge graph\n",
    "4. Store document vectors\n",
    "5. Update graph indices\n",
    "\n",
    "## Configuration\n",
    "- Document processing settings\n",
    "- Entity extraction parameters\n",
    "- Graph storage configuration\n",
    "- Vector storage settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path(\"../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import components\n",
    "from components.document_processor import DocumentProcessor\n",
    "from components.graph_store import GraphStore\n",
    "from components.vector_store import VectorStore\n",
    "from components.response_generator import ResponseGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def ingest_documents(\n",
    "    source_path: str,\n",
    "    rag_instance: Any,\n",
    "    metadata: Optional[Dict] = None,\n",
    "    batch_size: int = 100\n",
    ") -> None:\n",
    "    \"\"\"Process documents and construct graph representation.\n",
    "    \n",
    "    Args:\n",
    "        source_path: Path to file or directory\n",
    "        rag_instance: GraphRAG instance\n",
    "        metadata: Optional metadata to add to all documents\n",
    "        batch_size: Number of documents to process in each batch\n",
    "    \"\"\"\n",
    "    # Process documents\n",
    "    if os.path.isfile(source_path):\n",
    "        documents = rag_instance.doc_processor.process_files(\n",
    "            [source_path],\n",
    "            metadata=metadata\n",
    "        )\n",
    "    elif os.path.isdir(source_path):\n",
    "        documents = rag_instance.doc_processor.process_directory(\n",
    "            source_path,\n",
    "            metadata=metadata\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid source path: {source_path}\")\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(documents), batch_size), desc=\"Processing documents\"):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        \n",
    "        # Process each document\n",
    "        for doc in batch:\n",
    "            # Store in graph database\n",
    "            rag_instance.graph_store.store_document(\n",
    "                doc_id=doc[\"id\"],\n",
    "                content=doc[\"content\"],\n",
    "                metadata=doc[\"metadata\"],\n",
    "                graph_data=doc[\"graph_data\"]\n",
    "            )\n",
    "            \n",
    "            # Get document embedding\n",
    "            embedding = rag_instance.response_generator.llm.get_embedding(\n",
    "                doc[\"content\"]\n",
    "            )\n",
    "            \n",
    "            # Store in vector index\n",
    "            rag_instance.vector_store.store_document(\n",
    "                doc_id=doc[\"id\"],\n",
    "                content=doc[\"content\"],\n",
    "                vector=embedding,\n",
    "                metadata=doc[\"metadata\"]\n",
    "            )\n",
    "    \n",
    "    print(f\"Processed {len(documents)} documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
