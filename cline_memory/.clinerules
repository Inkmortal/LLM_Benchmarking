# Project Conventions & Patterns

## Code Organization

### 1. Notebook Structure
- Implementation notebooks split into ingestion and core logic
  - implementation.ipynb: Core RAG functionality
  - ingestion.ipynb: Document processing with Langchain
- Evaluation notebooks follow template structure
- Utility functions extracted to Python modules
- Documentation in markdown cells
- ALWAYS use write_to_file for notebook edits, never replace_in_file (it fails with notebook formatting)

### 2. Directory Conventions
- Datasets stored in `datasets/rag_evaluation/`
- Implementations in `rag_implementations/`
- Evaluation pipelines in `evaluation_pipelines/`
- Shared utilities in `utils/`

### 3. Git Practices
- Vector stores and datasets are git-ignored
- Documentation changes tracked
- Notebooks committed without output cells
- Large files handled via git-lfs

## Development Patterns

### 1. Document Processing
- Use Langchain for robust file handling
  - PyPDFLoader for PDFs
  - TextLoader for text files
  - Docx2txtLoader for Word docs
  - UnstructuredFileLoader as fallback
- Smart text chunking with RecursiveCharacterTextSplitter
- Preserve metadata through processing pipeline
- Process documents in batches for efficiency

### 2. AWS Integration
- Always use environment variables for credentials
- Implement rate limiting for API calls
- Handle service-specific errors
- Cache results where possible

### 3. Dataset Handling
- Download datasets through llama-index
- Cache locally to avoid re-downloads
- Track source files separately
- Preserve metadata during processing

### 4. Evaluation Process
- Use standardized templates
- Run benchmarks in batches
- Generate visual reports
- Document findings inline

## Common Pitfalls

### 1. Document Processing
- Large documents need proper chunking
- Metadata must be preserved through pipeline
- File encodings can cause issues
- Memory usage with large batches

### 2. AWS Services
- Rate limits can affect batch processing
- OpenSearch needs proper index settings
- Bedrock requires specific model IDs
- Neptune setup requires manual steps

### 3. Performance
- Large batches can trigger rate limits
- Caching improves repeated operations
- Memory usage grows with dataset size
- Async operations need proper handling

### 4. Documentation
- Keep notebooks self-contained
- Update docs with code changes
- Include usage examples
- Document error scenarios

## User Preferences

### 1. Development Environment
- Use Conda for environment management
- Jupyter notebooks for development
- VSCode as primary editor
- PowerShell for CLI operations

### 2. Code Style
- Type hints where beneficial
- Comprehensive docstrings
- Clear error messages
- Modular function design

### 3. Documentation
- Markdown for documentation
- Mermaid for diagrams
- Emoji for status indicators
- Tables for structured data

## Learned Patterns

### 1. Document Processing
- Split large documents into chunks
- Use smart text splitting
- Preserve document context
- Handle file types appropriately
- Process in batches for efficiency
- Cache processed documents

### 2. Effective Practices
- Split complex notebooks into stages
- Cache intermediate results
- Use progress bars for long operations
- Implement proper error handling

### 3. Optimization Tips
- Batch similar operations
- Cache embeddings
- Use async for API calls
- Monitor resource usage

### 4. Testing Strategies
- Start with small datasets
- Validate results incrementally
- Monitor performance metrics
- Document edge cases

## Project-Specific Notes

### 1. RAG Implementation
- Keep implementation and ingestion separate
- Pass chunking config from implementation to ingestion
- Use _store_documents for direct vector storage
- Keep files under 200 lines

### 2. Evaluation
- Use RAGAs metrics consistently
- Generate comprehensive reports
- Track performance over time
- Document anomalies

### 3. Documentation
- Keep docs updated with changes
- Include practical examples
- Document known issues
- Track resolved problems
