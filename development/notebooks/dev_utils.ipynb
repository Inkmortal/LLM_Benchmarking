{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Utilities Notebook\n",
    "\n",
    "This notebook provides utilities for testing and debugging during development, particularly focused on module reloading and utility testing.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Path Configuration\n",
    "2. Module Reloading Utilities\n",
    "3. Test Cases\n",
    "4. Example Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import pkgutil\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"Project root added to path: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def get_all_modules(package_name: str) -> List[str]:\n",
    "    \"\"\"Get all modules in a package recursively.\n",
    "    \n",
    "    Args:\n",
    "        package_name: Name of the package to scan (e.g., 'utils')\n",
    "        \n",
    "    Returns:\n",
    "        List of full module paths (e.g., ['utils.aws.opensearch_utils', ...])\n",
    "    \"\"\"\n",
    "    package = importlib.import_module(package_name)\n",
    "    modules = []\n",
    "    \n",
    "    if hasattr(package, '__path__'):\n",
    "        for loader, name, is_pkg in pkgutil.walk_packages(package.__path__, package_name + '.'):\n",
    "            try:\n",
    "                if not is_pkg:  # Only add leaf modules, not packages\n",
    "                    modules.append(name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing {name}: {str(e)}\")\n",
    "                \n",
    "    return sorted(modules)  # Sort for consistent order\n",
    "\n",
    "def reload_module(module_name: str) -> None:\n",
    "    \"\"\"Reload a module by name.\n",
    "    \n",
    "    Args:\n",
    "        module_name: Full module path (e.g., 'utils.notebook_utils.dataset_utils')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if module_name in sys.modules:\n",
    "            print(f\"Reloading {module_name}...\")\n",
    "            importlib.reload(sys.modules[module_name])\n",
    "        else:\n",
    "            print(f\"Importing {module_name}...\")\n",
    "            importlib.import_module(module_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reloading {module_name}: {str(e)}\")\n",
    "\n",
    "def clear_module_cache(module_prefix: str = 'utils') -> None:\n",
    "    \"\"\"Clear all cached modules with given prefix.\n",
    "    \n",
    "    Args:\n",
    "        module_prefix: Only clear modules starting with this prefix\n",
    "    \"\"\"\n",
    "    modules_to_clear = [m for m in sys.modules if m.startswith(module_prefix)]\n",
    "    for m in modules_to_clear:\n",
    "        del sys.modules[m]\n",
    "    print(f\"Cleared {len(modules_to_clear)} modules from cache\")\n",
    "\n",
    "def reload_all_utils() -> None:\n",
    "    \"\"\"Reload all utility modules automatically.\"\"\"\n",
    "    # Clear existing cache\n",
    "    clear_module_cache('utils')\n",
    "    \n",
    "    # Get all modules\n",
    "    modules = get_all_modules('utils')\n",
    "    print(f\"\\nFound {len(modules)} modules to reload:\")\n",
    "    for module in modules:\n",
    "        print(f\"- {module}\")\n",
    "    \n",
    "    # Reload each module\n",
    "    print(\"\\nReloading modules...\")\n",
    "    for module in modules:\n",
    "        reload_module(module)\n",
    "    \n",
    "    print(\"\\nAll utility modules reloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def test_dataset_utils():\n",
    "    \"\"\"Test dataset utilities functionality.\"\"\"\n",
    "    from utils.notebook_utils.dataset_utils import load_labeled_dataset, DATASET_REGISTRY\n",
    "    \n",
    "    print(\"Available datasets in registry:\")\n",
    "    for name, info in DATASET_REGISTRY.items():\n",
    "        print(f\"- {name}: {info['description']}\")\n",
    "    \n",
    "    # Test dataset loading\n",
    "    dataset_dir = project_root / \"datasets/rag_evaluation/labeled/covid19_origin\"\n",
    "    print(f\"\\nTesting dataset loading from {dataset_dir}\")\n",
    "    \n",
    "    try:\n",
    "        dataset, documents = load_labeled_dataset(dataset_dir, download_if_missing=True)\n",
    "        print(f\"Successfully loaded dataset with {len(dataset.examples)} examples and {len(documents)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "\n",
    "def run_all_tests():\n",
    "    \"\"\"Run all test cases.\"\"\"\n",
    "    print(\"Running dataset utils tests...\\n\")\n",
    "    test_dataset_utils()\n",
    "    print(\"\\nAll tests completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example: Update and Test Utils\n",
    "reload_all_utils()\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example: Debug Dataset Loading\n",
    "reload_all_utils()\n",
    "\n",
    "from utils.notebook_utils.dataset_utils import load_labeled_dataset\n",
    "\n",
    "dataset_dir = project_root / \"datasets/rag_evaluation/labeled/covid19_origin\"\n",
    "try:\n",
    "    dataset, documents = load_labeled_dataset(dataset_dir, download_if_missing=True)\n",
    "    print(f\"Success! Loaded {len(dataset.examples)} examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    print(\"\\nChecking directory structure:\")\n",
    "    print(f\"Dataset directory exists: {dataset_dir.exists()}\")\n",
    "    if dataset_dir.exists():\n",
    "        print(\"Contents:\")\n",
    "        for item in dataset_dir.glob(\"*\"):\n",
    "            print(f\"- {item.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
