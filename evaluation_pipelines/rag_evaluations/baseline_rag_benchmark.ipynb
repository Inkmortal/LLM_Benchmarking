{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline RAG Benchmarking\n",
    "\n",
    "This notebook benchmarks our baseline RAG implementation using the Origin of Covid-19 dataset.\n",
    "\n",
    "## Features\n",
    "- Automatic dataset loading\n",
    "- Document ingestion with caching\n",
    "- RAG evaluation using RAGAs metrics\n",
    "- Performance visualization\n",
    "\n",
    "## Process\n",
    "1. Load dataset if not already downloaded\n",
    "2. Process and ingest documents if not already in vector store\n",
    "3. Run evaluation\n",
    "4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path(\"../..\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import our RAG implementation\n",
    "from rag_implementations.baseline_rag.implementation import AWSConfig, BaselineRAG\n",
    "from rag_implementations.baseline_rag.ingestion import ingest_documents\n",
    "\n",
    "# Import utilities\n",
    "from utils.metrics.rag_metrics import calculate_metrics\n",
    "from utils.visualization.comparison_plots import plot_comparison_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class DatasetManager:\n",
    "    \"\"\"Manages dataset downloading and loading\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_name: str = \"OriginOfCovid19Dataset\"):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_dir = project_root / \"datasets/rag_evaluation/labeled/covid19_origin\"\n",
    "    \n",
    "    def ensure_dataset_exists(self) -> Tuple[Any, List[Dict[str, Any]]]:\n",
    "        \"\"\"Download dataset if it doesn't exist, otherwise load from disk\"\"\"\n",
    "        dataset_file = self.dataset_dir / \"rag_dataset.json\"\n",
    "        source_dir = self.dataset_dir / \"source_files\"\n",
    "        \n",
    "        if not dataset_file.exists() or not source_dir.exists():\n",
    "            print(f\"Downloading {self.dataset_name}...\")\n",
    "            from llama_index.core.llama_dataset import download_llama_dataset\n",
    "            return download_llama_dataset(self.dataset_name, str(self.dataset_dir))\n",
    "        else:\n",
    "            print(f\"Loading existing dataset from {self.dataset_dir}...\")\n",
    "            from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "            from llama_index.core import SimpleDirectoryReader\n",
    "            \n",
    "            dataset = LabelledRagDataset.from_json(str(dataset_file))\n",
    "            documents = SimpleDirectoryReader(str(source_dir)).load_data()\n",
    "            return dataset, documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class VectorStoreManager:\n",
    "    \"\"\"Manages vector store operations\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_name: str):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.index_name = f\"{dataset_name.lower()}-rag-documents\"\n",
    "    \n",
    "    def is_ingested(self, rag_system: BaselineRAG) -> bool:\n",
    "        \"\"\"Check if documents are already ingested\"\"\"\n",
    "        try:\n",
    "            # Try to get a document count\n",
    "            response = rag_system.config.opensearch.count(index=self.index_name)\n",
    "            return response['count'] > 0\n",
    "        except Exception:\n",
    "            return False\n",
    "    \n",
    "    def prepare_documents(self, documents: List[Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Prepare documents for ingestion\"\"\"\n",
    "        prepared_docs = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            prepared_docs.append({\n",
    "                'content': doc.text,\n",
    "                'metadata': {\n",
    "                    'dataset': self.dataset_name,\n",
    "                    **doc.metadata\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        return prepared_docs\n",
    "    \n",
    "    def ingest_if_needed(self, rag_system: BaselineRAG, documents: List[Any]):\n",
    "        \"\"\"Ingest documents if not already in vector store\"\"\"\n",
    "        if not self.is_ingested(rag_system):\n",
    "            print(\"Ingesting documents...\")\n",
    "            prepared_docs = self.prepare_documents(documents)\n",
    "            rag_system.ingest_documents(prepared_docs)\n",
    "        else:\n",
    "            print(\"Documents already ingested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_rag(rag_system: BaselineRAG, dataset, num_samples: Optional[int] = None) -> Dict:\n",
    "    \"\"\"Evaluate RAG system using dataset\"\"\"\n",
    "    examples = dataset.examples\n",
    "    if num_samples:\n",
    "        from random import sample\n",
    "        examples = sample(examples, min(num_samples, len(examples)))\n",
    "    \n",
    "    results = []\n",
    "    for example in tqdm(examples, desc=\"Evaluating\"):\n",
    "        response = rag_system.query(example.query)\n",
    "        \n",
    "        metrics = calculate_metrics(\n",
    "            query=example.query,\n",
    "            response=response['response'],\n",
    "            context=response['context'],\n",
    "            ground_truth=example.reference_answer\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'query': example.query,\n",
    "            'response': response['response'],\n",
    "            'ground_truth': example.reference_answer,\n",
    "            'context': response['context'],\n",
    "            'metrics': metrics\n",
    "        })\n",
    "    \n",
    "    # Aggregate metrics\n",
    "    aggregated = {\n",
    "        metric: sum(r['metrics'][metric] for r in results) / len(results)\n",
    "        for metric in results[0]['metrics'].keys()\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'individual_results': results,\n",
    "        'aggregated_metrics': aggregated\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configuration\n",
    "DATASET_NAME = \"OriginOfCovid19Dataset\"\n",
    "NUM_EVAL_SAMPLES = None  # Set to a number for partial evaluation\n",
    "\n",
    "# Initialize managers\n",
    "dataset_manager = DatasetManager(DATASET_NAME)\n",
    "vector_store_manager = VectorStoreManager(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load or download dataset\n",
    "dataset, documents = dataset_manager.ensure_dataset_exists()\n",
    "print(f\"Dataset loaded: {len(dataset.examples)} examples, {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize RAG system and ingest documents if needed\n",
    "config = AWSConfig()\n",
    "rag = BaselineRAG(config, index_name=vector_store_manager.index_name)\n",
    "vector_store_manager.ingest_if_needed(rag, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run evaluation\n",
    "print(\"Running evaluation...\")\n",
    "results = evaluate_rag(rag, dataset, num_samples=NUM_EVAL_SAMPLES)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nAggregated Metrics:\")\n",
    "for metric, value in results['aggregated_metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save results\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "results_data = {\n",
    "    'dataset': DATASET_NAME,\n",
    "    'num_examples': len(dataset.examples),\n",
    "    'num_documents': len(documents),\n",
    "    'num_evaluated': len(results['individual_results']),\n",
    "    'results': results\n",
    "}\n",
    "\n",
    "with open(results_dir / 'baseline_rag_results.json', 'w') as f:\n",
    "    json.dump(results_data, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {results_dir / 'baseline_rag_results.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize results\n",
    "plot_comparison_results(\n",
    "    {\n",
    "        'Baseline RAG': results['aggregated_metrics']\n",
    "    },\n",
    "    title=f'RAG Evaluation Results ({DATASET_NAME})'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example queries\n",
    "example_queries = [\n",
    "    \"What is the main focus of the article 'The Origin of COVID-19 and Why It Matters'?\",\n",
    "    \"What evidence suggests that SARS-CoV-2 emerged naturally rather than being engineered?\",\n",
    "    \"What are some potential consequences of not understanding how COVID-19 emerged?\"\n",
    "]\n",
    "\n",
    "print(\"Testing example queries...\\n\")\n",
    "for query in example_queries:\n",
    "    print(f\"Query: {query}\")\n",
    "    result = rag.query(query)\n",
    "    print(f\"Response: {result['response']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
